{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preliminary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Plotting model architecture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualize filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = model.layers[0]\n",
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Activation Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Maximal Activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# Utility to search for layer index by name.\n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'preds')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)\n",
    "\n",
    "# This is the output node we want to maximize.\n",
    "filter_idx = 0\n",
    "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
    "plt.imshow(img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_idx in np.arange(10):\n",
    "   # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
    "   img = visualize_activation(model, layer_idx, filter_indices=output_idx, input_range=(0., 1.))\n",
    "   plt.figure()\n",
    "   plt.title('Networks perception of {}'.format(output_idx))\n",
    "   plt.imshow(img[..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Image Occlusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_occlusion(image, size=8):\n",
    "    # taken from https://www.kaggle.com/blargl/simple-occlusion-and-saliency-maps\n",
    "\n",
    "   occlusion = np.full((size * 5, size * 5, 1), [0.5], np.float32)\n",
    "   occlusion_center = np.full((size, size, 1), [0.5], np.float32)\n",
    "   occlusion_padding = size * 2\n",
    "\n",
    "   # print('padding...')\n",
    "   image_padded = np.pad(image, ( \\\n",
    "   (occlusion_padding, occlusion_padding), (occlusion_padding, occlusion_padding), (0, 0) \\\n",
    "   ), 'constant', constant_values = 0.0)\n",
    "\n",
    "   for y in range(occlusion_padding, image.shape[0] + occlusion_padding, size):\n",
    "\n",
    "       for x in range(occlusion_padding, image.shape[1] + occlusion_padding, size):\n",
    "           tmp = image_padded.copy()\n",
    "\n",
    "           tmp[y - occlusion_padding:y + occlusion_center.shape[0] + occlusion_padding, \\\n",
    "             x - occlusion_padding:x + occlusion_center.shape[1] + occlusion_padding] \\\n",
    "             = occlusion\n",
    "\n",
    "           tmp[y:y + occlusion_center.shape[0], x:x + occlusion_center.shape[1]] = occlusion_center\n",
    "\n",
    "           yield x - occlusion_padding, y - occlusion_padding, \\\n",
    "             tmp[occlusion_padding:tmp.shape[0] - occlusion_padding, occlusion_padding:tmp.shape[1] - occlusion_padding]\n",
    "\n",
    "i = 23 # for example\n",
    "data = val_x[i]\n",
    "correct_class = np.argmax(val_y[i])\n",
    "\n",
    "# input tensor for model.predict\n",
    "inp = data.reshape(1, 28, 28, 1)\n",
    "\n",
    "# image data for matplotlib's imshow\n",
    "img = data.reshape(28, 28)\n",
    "\n",
    "# occlusion\n",
    "img_size = img.shape[0]\n",
    "occlusion_size = 4\n",
    "\n",
    "print('occluding...')\n",
    "\n",
    "heatmap = np.zeros((img_size, img_size), np.float32)\n",
    "class_pixels = np.zeros((img_size, img_size), np.int16)\n",
    "\n",
    "from collections import defaultdict\n",
    "counters = defaultdict(int)\n",
    "\n",
    "for n, (x, y, img_float) in enumerate(iter_occlusion(data, size=occlusion_size)):\n",
    "\n",
    "    X = img_float.reshape(1, 28, 28, 1)\n",
    "    out = model.predict(X)\n",
    "    #print('#{}: {} @ {} (correct class: {})'.format(n, np.argmax(out), np.amax(out), out[0][correct_class]))\n",
    "    #print('x {} - {} | y {} - {}'.format(x, x + occlusion_size, y, y + occlusion_size))\n",
    "\n",
    "    heatmap[y:y + occlusion_size, x:x + occlusion_size] = out[0][correct_class]\n",
    "    class_pixels[y:y + occlusion_size, x:x + occlusion_size] = np.argmax(out)\n",
    "    counters[np.argmax(out)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Based Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Saliency Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = 0\n",
    "indices = np.where(val_y[:, class_idx] == 1.)[0]\n",
    "\n",
    "# pick some random input from here.\n",
    "idx = indices[0]\n",
    "\n",
    "# Lets sanity check the picked image.\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "plt.imshow(val_x[idx][..., 0])\n",
    "\n",
    "\n",
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "# Utility to search for layer index by name. \n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'preds')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)\n",
    "\n",
    "grads = visualize_saliency(model, layer_idx, filter_indices=class_idx, seed_input=val_x[idx])\n",
    "# Plot with 'jet' colormap to visualize as a heatmap.\n",
    "plt.imshow(grads, cmap='jet')\n",
    "\n",
    "\n",
    "# This corresponds to the Dense linear layer.\n",
    "for class_idx in np.arange(10): \n",
    "    indices = np.where(val_y[:, class_idx] == 1.)[0]\n",
    "    idx = indices[0]\n",
    "\n",
    "    f, ax = plt.subplots(1, 4)\n",
    "    ax[0].imshow(val_x[idx][..., 0])\n",
    " \n",
    "    for i, modifier in enumerate([None, 'guided', 'relu']):\n",
    "        grads = visualize_saliency(model, layer_idx, filter_indices=class_idx, \n",
    "        seed_input=val_x[idx], backprop_modifier=modifier)\n",
    "        if modifier is None:\n",
    "            modifier = 'vanilla'\n",
    "        ax[i+1].set_title(modifier) \n",
    "        ax[i+1].imshow(grads, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Gradient based Class Activations Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_cam\n",
    "\n",
    "# This corresponds to the Dense linear layer.\n",
    "for class_idx in np.arange(10): \n",
    " indices = np.where(val_y[:, class_idx] == 1.)[0]\n",
    " idx = indices[0]\n",
    "\n",
    "f, ax = plt.subplots(1, 4)\n",
    " ax[0].imshow(val_x[idx][..., 0])\n",
    " \n",
    "for i, modifier in enumerate([None, 'guided', 'relu']):\n",
    "    grads = visualize_cam(model, layer_idx, filter_indices=class_idx, \n",
    "    seed_input=val_x[idx], backprop_modifier=modifier) \n",
    "    if modifier is None:\n",
    "        modifier = 'vanilla'\n",
    "    ax[i+1].set_title(modifier) \n",
    "    ax[i+1].imshow(grads, cmap='jet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
